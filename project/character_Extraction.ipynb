{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a1c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pythonprogramming.net/named-entity-recognition-stanford-ner-tagger/\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('./stanford-ner/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                        './stanford-ner/stanford-ner.jar',\n",
    "                       encoding='utf-8')\n",
    "\n",
    "text = 'While in France, Christine Lagarde and Duffy and Hestia discussed short-term stimulus efforts in a recent interview with the Wall Street Journal.'\n",
    "\n",
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6f4249",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pdfminersix.readthedocs.io/en/latest/tutorial/highlevel.html\n",
    "\n",
    "pages = list(range(5, 14))\n",
    "\n",
    "from pdfminer.high_level import extract_text\n",
    "text = extract_text('./Books/Harry_Potter_and_the_Deathly_Hallows.pdf', page_numbers=pages)\n",
    "#print(text)\n",
    "\n",
    "tokenized_text1 = word_tokenize(text)\n",
    "classified_text1 = st.tag(tokenized_text1)\n",
    "\n",
    "print(classified_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeae91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = []\n",
    "organizations = []\n",
    "locations = []\n",
    "\n",
    "for word, type in classified_text1:\n",
    "    if type == 'PERSON':\n",
    "        persons.append(word)\n",
    "    if type == 'ORGANIZATION':\n",
    "        organizations.append(word)\n",
    "    if type == 'LOCATION':\n",
    "        locations.append(word)\n",
    "print(persons)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(organizations)\n",
    "print(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eadf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract books and save chapterwise as txt\n",
    "\n",
    "chp_starts = [5, 14, 25, 35, 49, 66, 84, 103, 120, 131, 149, 165, 182, 198, 209, 229, 243, 258, 267, 285, 298, \n",
    "            311, 327, 349, 367, 379, 397, 404, 416, 429, 443, 464, 479, 502, 512, 526, 545, 550]\n",
    "\n",
    "for i in range(len(chp_starts)-1):\n",
    "    pages = list(range(chp_starts[i], chp_starts[i+1]))\n",
    "    text = extract_text('./Books/Harry_Potter_and_the_Deathly_Hallows.pdf', page_numbers=pages)\n",
    "    chapter = open(\"B7_Ch\" + str(i+1)+\".txt\", \"w\")\n",
    "    n = chapter.write(text)\n",
    "    chapter.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"sample.txt\", \"w\")\n",
    "n = text_file.write('Welcome to pythonexamples.org')\n",
    "text_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
