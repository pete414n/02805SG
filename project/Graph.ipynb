{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09732d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import csv\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from community import community_louvain\n",
    "from fa2 import ForceAtlas2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a0c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character tuple list\n",
    "\n",
    "characters = []\n",
    "\n",
    "with open(\"HP_characters.csv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    csv_file = csv.reader(sent_file, delimiter=\",\")\n",
    "    for row in csv_file:\n",
    "        name = row[0].replace(' ', '_')\n",
    "        # lower to make sure they are spelled the same way\n",
    "        parentage = row[1].lower()\n",
    "        house = row[2].lower()\n",
    "        occupation = row[3].lower()\n",
    "        characters.append((name, parentage, house, occupation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cde76f5",
   "metadata": {},
   "source": [
    "# Graph with weights\n",
    "Making a graphs for each book. The nodes are the characters in the book, and edges are between characters that are in the same chapter. Edges have weight corresponding to the number of times those two characters are in the same chapter. Nodes have the attributes parentage, house and occupation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: A list of character names with their attributes, \n",
    "       the path of the book,\n",
    "       how many sentences to look at at time\n",
    "Output: A weighted graph\n",
    "\"\"\"\n",
    "def weighted_temporal_graphs(character_list, path, sentence_no):\n",
    "    \n",
    "    G = nx.Graph()\n",
    "  \n",
    "    # Go throug each chapter in the book\n",
    "    for chapter in os.listdir(path): \n",
    "        #only look at the files where aliases have been replaced with character names\n",
    "        if \"replaced\" in chapter:   \n",
    "\n",
    "            # Get text\n",
    "            with open(path + chapter) as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            # Put all characters from the chapter in the graph if they are not already there\n",
    "            for character in character_list:\n",
    "                if character[0] in text and character[0] not in list(G.nodes):\n",
    "                    G.add_node(character[0], parentage = character[1], \n",
    "                               house = character[2], occupation = character[3])\n",
    "            \n",
    "            # Split the text in sentences \n",
    "            sentences = text.split(\". \")\n",
    "            count_start = 0\n",
    "            count_end = sentence_no\n",
    "            \n",
    "            # Look at specified amount of senteces at a time\n",
    "            while (count_start < len(sentences)):\n",
    "                current = sentences[count_start:count_end]\n",
    "                current = \" \".join(current)\n",
    "                \n",
    "                # Go through the nodes and check if two diffferent nodes appear in the same text piece\n",
    "                # if so add an edge\n",
    "                # weight is the amount of times they appear together throughout the book\n",
    "                for character_source in list(G.nodes):\n",
    "                    #print(character_source)\n",
    "                    for character_target in list(G.nodes):\n",
    "                        #print(character_target)\n",
    "                        if character_source is character_target:\n",
    "                            continue\n",
    "                        elif (character_source in current and character_target in current):\n",
    "                            if G.has_edge(character_source, character_target):\n",
    "                                G[character_source][character_target]['weight'] += 1\n",
    "                            else:\n",
    "                                G.add_edge(character_source, character_target, weight=1)\n",
    "                            #print(\"added some edge\")\n",
    "                count_start = count_end\n",
    "                count_end += sentence_no\n",
    "    # Remove nodes without edges\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    #print(\"Done with graph\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19383129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.operators.binary.compose.html#networkx.algorithms.operators.binary.compose\n",
    "\n",
    "\"\"\"\n",
    "Input: two graphs to combine\n",
    "Output: the combined graph, including the weights of the edges added together if same edges\n",
    "\"\"\"\n",
    "\n",
    "def combine_graphs(g1, g2):\n",
    "    combined= nx.compose(g1, g2)\n",
    "    edge_data = {e: g1.edges[e]['weight'] + g2.edges[e]['weight'] \n",
    "                 for e in g1.edges & g2.edges}\n",
    "    nx.set_edge_attributes(combined, edge_data, 'weight')\n",
    "    \n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Input: a graph\n",
    "Output: A list of of the summed weights for the edges for each node,\n",
    "        this list is ordered as the list of nodes returned from graph.nodes\n",
    "\"\"\"\n",
    "def get_weight_sums(graph):\n",
    "    weight_sums = []\n",
    "    for node in list(graph.nodes):\n",
    "        sum = 0\n",
    "        for source, target in list(graph.edges):\n",
    "            if node is source or node is target:\n",
    "                sum += graph[source][target][\"weight\"]\n",
    "        weight_sums.append(sum)\n",
    "    return weight_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: a graph,\n",
    "       title for the plot, default is empty string\n",
    "Output: plots the graph using forceAtlas\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def draw_network(graph, title=\"\"):\n",
    "    # Adjusting figure size\n",
    "    plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "    forceatlas2 = ForceAtlas2(\n",
    "                            # Behavior alternatives\n",
    "                            outboundAttractionDistribution=True,  # Dissuade hubs\n",
    "                            linLogMode=False,  # NOT IMPLEMENTED\n",
    "                            adjustSizes=False,  # Prevent overlap (NOT IMPLEMENTED)\n",
    "                            edgeWeightInfluence=1.0,\n",
    "\n",
    "                            # Performance\n",
    "                            jitterTolerance=1.0,  # Tolerance\n",
    "                            barnesHutOptimize=True,\n",
    "                            barnesHutTheta=1.2, # original 1.2\n",
    "                            multiThreaded=False,  # NOT IMPLEMENTED\n",
    "\n",
    "                            # Tuning\n",
    "                            scalingRatio=2.0,\n",
    "                            strongGravityMode=True,\n",
    "                            gravity=0.1, # original 0.5\n",
    "\n",
    "                            # Log\n",
    "                            verbose=True)\n",
    "\n",
    "    positions = forceatlas2.forceatlas2_networkx_layout(graph, pos=None, iterations=2000)\n",
    "    nx.draw_networkx_nodes(graph, positions, node_color=\"red\", node_size=get_weight_sums(graph), alpha=0.4)\n",
    "    nx.draw_networkx_edges(graph, positions, edge_color=\"green\", alpha=0.05)\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.figtext(.5, -0.05, f\"The size of a note indicates the sum of its weights.\", ha=\"center\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eee5466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making graphs of book 1 where the no of senteces are changed\n",
    "\n",
    "graph_list = []\n",
    "#(character_list, path, graph_list, sentence_no):\n",
    "graph_list.append(weighted_temporal_graphs(characters, \"B1/\", 5))\n",
    "graph_list.append(weighted_temporal_graphs(characters, \"B1/\", 10))\n",
    "graph_list.append(weighted_temporal_graphs(characters, \"B1/\", 20))\n",
    "graph_list.append(weighted_temporal_graphs(characters, \"B1/\", 30))\n",
    "graph_list.append(weighted_temporal_graphs(characters, \"B1/\", 40))\n",
    "graph_list.append(weighted_temporal_graphs(characters, \"B1/\", 50))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5f8de1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting the networks with different no of sentences\n",
    "sentence_len = [5, 10, 20, 30, 40, 50]\n",
    "\n",
    "for i, graph in enumerate(graph_list):\n",
    "    draw_network(graph, \"Book one network with interval of \"+str(sentence_len[i])+\" sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making network separately for each book\n",
    "\n",
    "book_graphs = []\n",
    "\n",
    "book_graphs.append(weighted_temporal_graphs(characters, \"B1/\", 5))\n",
    "book_graphs.append(weighted_temporal_graphs(characters, \"B2/\", 5))\n",
    "book_graphs.append(weighted_temporal_graphs(characters, \"B3/\", 5))\n",
    "book_graphs.append(weighted_temporal_graphs(characters, \"B4/\", 5))\n",
    "book_graphs.append(weighted_temporal_graphs(characters, \"B5/\", 5))\n",
    "book_graphs.append(weighted_temporal_graphs(characters, \"B6/\", 5))\n",
    "book_graphs.append(weighted_temporal_graphs(characters, \"B7/\", 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e500df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drawing network of each book\n",
    "for i, graph in enumerate(book_graphs):\n",
    "    draw_network(graph, \"Network of book \" + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5609f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the networks of the books\n",
    "combined_nx = [book_graphs[0]]\n",
    "combined_nx.append(combine_graphs(combined_nx[0], book_graphs[1]))\n",
    "combined_nx.append(combine_graphs(combined_nx[1], book_graphs[2]))\n",
    "combined_nx.append(combine_graphs(combined_nx[2], book_graphs[3]))\n",
    "combined_nx.append(combine_graphs(combined_nx[3], book_graphs[4]))\n",
    "combined_nx.append(combine_graphs(combined_nx[4], book_graphs[5]))\n",
    "combined_nx.append(combine_graphs(combined_nx[5], book_graphs[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056f3012",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Drawing network of combined books\n",
    "for i, graph in enumerate(combined_nx):\n",
    "    title = ''\n",
    "    if i == 0:\n",
    "        title = \"Network of book 1\"\n",
    "    else:\n",
    "        title = \"Network of book 1-\" + str(i+1) \n",
    "    draw_network(graph, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of nodes and edges in each combined network\n",
    "\n",
    "for i, graph in enumerate(combined_nx):\n",
    "    title = ''\n",
    "    if i == 0:\n",
    "        title = \" edges in the network of book 1\"\n",
    "    else:\n",
    "        title = \" edges in the network of book 1-\" + str(i+1) \n",
    "    print('There are ' +str(graph.number_of_nodes()) + ' and ' + str(graph.number_of_edges()) + title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735863d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting on making a plot to show how nodes and edges increase throughout the book series\n",
    "no_nodes = []\n",
    "no_edges = []\n",
    "networks = [1, 2, 3, 4, 5, 6, 7]\n",
    "for graph in combined_nx:\n",
    "    no_nodes.append(graph.number_of_nodes())\n",
    "    no_edges.append(graph.number_of_edges())\n",
    "\n",
    "ax1 = plt.subplot()\n",
    "l1, = ax1.plot(networks, no_nodes, color='red')\n",
    "ax2 = ax1.twinx()\n",
    "l2, = ax2.plot(networks, no_edges, color='blue')\n",
    "ax1.set_xlabel('No. of books combined')\n",
    "ax1.tick_params(axis=\"y\", labelcolor='red')\n",
    "ax2.tick_params(axis=\"y\", labelcolor='blue')\n",
    "ax1.set_ylabel(\"No. of nodes\")\n",
    "ax2.set_ylabel(\"No. of edges\")\n",
    "\n",
    "plt.legend([l1, l2], [\"No. of nodes\", \"No. of edges\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1ffacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HP, RW, HG, AD, Snape, Voldemort, Hagrid, draco malfoy, ginny weaslye, necille longbottom\n",
    "\n",
    "# PLotting number of edges belong to ten characters throughout the series:\n",
    "char = [\"Harry_Potter\", \"Ronald_Weasley\", \"Hermione_Granger\", \"Albus_Dumbledore\", \"Severus_Snape\", \"Tom_Riddle\", \n",
    "        \"Rubeus_Hagrid\", \"Draco_Malfoy\", \"Ginevra_Weasley\", \"Neville_Longbottom\"]\n",
    "\n",
    "no_edges = []\n",
    "networks = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "for c in char:\n",
    "    edges = []\n",
    "    for graph in combined_nx:\n",
    "        edges.append(len(list(graph.edges(c))))\n",
    "    no_edges.append(edges)\n",
    "\n",
    "for i, e_list in enumerate(no_edges):\n",
    "    plt.plot(networks, e_list, label = char[i].replace('_', ' '))\n",
    "plt.xlabel(\"No. of books combined\")\n",
    "plt.ylabel(\"No. of edges\")\n",
    "plt.title(\"Evolution of the network of ten main characters\")\n",
    "plt.legend(fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d923af",
   "metadata": {},
   "source": [
    "## Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62220943",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: a graph to divide in communities\n",
    "Output: A list with the different communities\n",
    "\"\"\"\n",
    "\n",
    "def communities(graph):\n",
    "    partition = community_louvain.best_partition(graph)\n",
    "    #print(partition)\n",
    "    partition_list = []\n",
    "    \n",
    "    for com in set(partition.values()) :\n",
    "        list_nodes = [nodes for nodes in partition.keys()\n",
    "                                if partition[nodes] == com]\n",
    "        partition_list.append(list_nodes)\n",
    "    partition_list = sorted(partition_list, key=len, reverse=True)\n",
    "    #print(partition_list)\n",
    "    return partition_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736cc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: a community and the graph it is extracted from\n",
    "Output: A dictionary of all the characters in the community,\n",
    "        the parentages, houses and occupations belonging to the characters.\n",
    "        Each character gets a value according to their sum\n",
    "        Each parentage, house and accupation is summed up for the total no. of characters belonging\n",
    "        to that parentage, house or occupation.\n",
    "\"\"\"\n",
    "\n",
    "#Make dictionary wordclouds with the character names and their weights\n",
    "# equal attributes are summarized\n",
    "\n",
    "def wordcloud_dict(community, graph):\n",
    "    cloud_freq = {}   \n",
    "    subG = graph.subgraph(community)\n",
    "    nodes = list(subG.nodes)\n",
    "    weights = get_weight_sums(subG)\n",
    "    parentages = nx.get_node_attributes(subG, 'parentage')\n",
    "    houses = nx.get_node_attributes(subG, 'house')\n",
    "    occupations = nx.get_node_attributes(subG, 'occupation')\n",
    "    \n",
    "    \n",
    "    for character in community:\n",
    "        parentage = parentages[character]\n",
    "        house = houses[character]\n",
    "        occupation = occupations[character]\n",
    "        \n",
    "        cloud_freq[character.replace('_', ' ')] = weights[nodes.index(character)]\n",
    "        \n",
    "        if parentage != 'other':\n",
    "            if parentage in cloud_freq:\n",
    "                cloud_freq[parentage] = cloud_freq.get(parentage) + 1\n",
    "            else:\n",
    "                cloud_freq[parentage] = 1\n",
    "        \n",
    "        if house != 'other':\n",
    "            if house in cloud_freq:\n",
    "                cloud_freq[house] = cloud_freq.get(house) + 1\n",
    "            else:\n",
    "                cloud_freq[house] = 1\n",
    "        \n",
    "        if occupation != 'other':\n",
    "            if occupation in cloud_freq:\n",
    "                cloud_freq[occupation] = cloud_freq.get(occupation) + 1\n",
    "            else:\n",
    "                cloud_freq[occupation] = 1\n",
    "    \n",
    "    return cloud_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58508f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: a list of communities and the graph they're extracted from\n",
    "Output: a list with a dictionary for each community\n",
    "\"\"\"\n",
    "\n",
    "def make_com_dicts(com_list, graph):\n",
    "    com_dicts = []\n",
    "\n",
    "    for com in com_list:\n",
    "        com_dicts.append(wordcloud_dict(com, graph))\n",
    "    \n",
    "    return com_dicts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce063ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: a list of dictionaries\n",
    "Output: Wordclouds plotted for the community dictionaries given\n",
    "\"\"\"\n",
    "def draw_word_cloud(dicts):\n",
    "    fig = plt.figure()\n",
    "    plt.rcParams['figure.figsize'] = [15, 20]\n",
    "\n",
    "    for i in range(len(dicts)):\n",
    "        ax = fig.add_subplot(5,2,i+1)\n",
    "        wordcloud = WordCloud(background_color='black', width=2200,\n",
    "                          height=1800, collocations=False).generate_from_frequencies(dicts[i])\n",
    "\n",
    "        ax.imshow(wordcloud)\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6df728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Communitites from all books\n",
    "all_communities = communities(combined_nx[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17524d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb53750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# communities in each book:\n",
    "\n",
    "book_communities = []\n",
    "\n",
    "for graph in book_graphs:\n",
    "    book_communities.append(communities(graph))\n",
    "    \n",
    "#print(len(book_communities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95475a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print which book, the communities and the size of each community\n",
    "\n",
    "for i, com in enumerate(book_communities):\n",
    "    print('Book no.: ' + str(i+1))\n",
    "    print(com)\n",
    "    for part in com:\n",
    "        print(len(part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0152fb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordclouds for all books combined\n",
    "dictionary = make_com_dicts(all_communities, combined_nx[6])\n",
    "draw_word_cloud(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311cda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordclouds for book 1:\n",
    "dictionary = make_com_dicts(book_communities[0], book_graphs[0])\n",
    "draw_word_cloud(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bdc490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordclouds for book 2:\n",
    "dictionary = make_com_dicts(book_communities[1], book_graphs[1])\n",
    "draw_word_cloud(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordclouds for book 3:\n",
    "dictionary = make_com_dicts(book_communities[2], book_graphs[2])\n",
    "draw_word_cloud(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4ffcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordclouds for book 4:\n",
    "dictionary = make_com_dicts(book_communities[3], book_graphs[3])\n",
    "draw_word_cloud(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8244e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordclouds for book 5:\n",
    "dictionary = make_com_dicts(book_communities[4], book_graphs[4])\n",
    "draw_word_cloud(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc093c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordclouds for book 6:\n",
    "dictionary = make_com_dicts(book_communities[5], book_graphs[5])\n",
    "draw_word_cloud(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wordclouds for book 7:\n",
    "dictionary = make_com_dicts(book_communities[6], book_graphs[6])\n",
    "draw_word_cloud(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c22042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52a3f7b6",
   "metadata": {},
   "source": [
    "### Probably not gonna be used. It is if we want to extract text belonging to the character in a community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e121d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Putting together the text from the pages belonging to each community\n",
    "community_texts = []\n",
    "maxrange = 0\n",
    "#if we have less than 10 communities\n",
    "if len(partition_list) < 10:\n",
    "    maxrange = len(partition_list)\n",
    "else:\n",
    "    maxrange = 10\n",
    "    \n",
    "for sublist in partition_list[:maxrange]:\n",
    "    com_txt = []\n",
    "    for character in sublist:\n",
    "        f = open(\"./characters/\"+character+\".txt\")\n",
    "        raw = f.read()\n",
    "        tokens = nltk.wordpunct_tokenize(BeautifulSoup(raw, 'html.parser').get_text())\n",
    "        file_text = [w.lower() for w in tokens if w.isalpha()]\n",
    "        com_txt = com_txt + file_text\n",
    "    community_texts.append(com_txt)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "community_strings = []\n",
    "for txt in community_texts:\n",
    "    com_words = [w for w in txt if w not in stopwords]\n",
    "    community_strings.append(com_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f75fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_terms = []\n",
    "for community_words in community_strings:\n",
    "    unique_terms.append(list(set(community_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c30fb76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc0a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# communities from fandom\n",
    "f = open(\"communities_from_fandom.csv\", \"w\")\n",
    "for character, community in list(partition.items()): \n",
    "    f.write(character + \",\" + str(community) + \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e4c5d",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5358bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word, unique_list):\n",
    "    N = len(unique_list)\n",
    "    term_appears = 0\n",
    "    for sublist in unique_list:\n",
    "        if word in sublist:\n",
    "            term_appears+=1\n",
    "    idf_val = math.log(N/(1+term_appears))+1\n",
    "    return idf_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a7cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the tf list\n",
    "tfidf_list = []\n",
    "\n",
    "for community_words in community_strings:\n",
    "    fdist = FreqDist(community_words)\n",
    "    total_terms = len(community_words)\n",
    "    tfidf=[]\n",
    "    for word in fdist:\n",
    "        idf_val = idf(word, unique_terms)\n",
    "        tf_val = fdist[word]/total_terms\n",
    "        tfidf_elem=(word, tf_val*idf_val)\n",
    "        tfidf.append(tfidf_elem)\n",
    "    tfidf_list.append(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a282b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.rcParams['figure.figsize'] = [15, 20]\n",
    "\n",
    "for i in range(len(tfidf_list)):\n",
    "    ax = fig.add_subplot(5,2,i+1)\n",
    "    wordcloud = WordCloud(background_color='black', width=2200,\n",
    "                      height=1800, collocations=False).generate_from_frequencies(dict(tfidf_list[i]))\n",
    "\n",
    "    ax.imshow(wordcloud)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d16ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
