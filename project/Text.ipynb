{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce307b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import csv\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from community import community_louvain\n",
    "from fa2 import ForceAtlas2\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b56336",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    ">We want to be able to analyse the sentiment of a character throughout the books. Our idea for achieving this is to use concordance from nltk with the character name, this way we will get all of the context surrounding a character. For each of these occurrences we can compute the sentiment for the context, and use that sentiment as a representative for the character. This could be done on occurence basis, but since we are expecting to have many occurences how harry, and fewer for other main characters, and even less for the remaining characters, this would require additional steps to normalize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5816beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for chapter in os.listdir(\"B7/\"):\n",
    "    f = open(\"B7/\" + chapter)\n",
    "    raw = f.read()\n",
    "    tokens += nltk.wordpunct_tokenize(raw)\n",
    "text = nltk.Text(tokens)\n",
    "\n",
    "text.dispersion_plot([\"Harry\", \"Voldemort\", \"Snape\", \"Luna\", \"Neville\", \"Nagini\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd021b74",
   "metadata": {},
   "source": [
    "##  Sentiment for concordance of character, LabMT1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "\n",
    "# Get characters and communities, according to fandom graph\n",
    "with open(\"communities_from_fandom.csv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    csv = csv.reader(sent_file, delimiter=\",\")\n",
    "    for row in csv:\n",
    "        name = row[0]\n",
    "        community = row[1]\n",
    "        characters.append((name, community))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Create an empty list to store tuples of words and their \n",
    "# average happiness score\n",
    "sent_list = []\n",
    "\n",
    "# Read in the .tsv file\n",
    "with open(\"LabMT1.0.tsv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    tsv_reader = csv.DictReader(sent_file, delimiter=\"\\t\")\n",
    "    # For each sentiment in the file, save the word and average happiness in a tuple\n",
    "    # and add it to the list\n",
    "    for sent in tsv_reader:\n",
    "        word = sent[\"word\"]\n",
    "        average = sent[\"happiness_average\"]\n",
    "        sent_list.append((word, average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cceb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to calculate sentiment for a list of tokens\n",
    "# Function for calculating the sentiment of a file from the frequency distribution for that file\n",
    "def sentiment(tokens):\n",
    "    # Total sentiment score of file\n",
    "    sent_sum = 0.0\n",
    "    # Total number of occurences of words\n",
    "    occ_sum = 0\n",
    "    \n",
    "    # For each token and associated number of occurences\n",
    "    for token, occ in tokens.items():\n",
    "        # If the token is in the given list of words with rated happiness\n",
    "        for word, score in sent_list:\n",
    "            if token == word:\n",
    "                sent_sum += (float(score) * occ)\n",
    "                occ_sum += occ\n",
    "    return sent_sum / occ_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b7416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding sentiment from a concordance list\n",
    "def con_sentiment(con_list):\n",
    "    sent_sum = 0\n",
    "    line_num = 0\n",
    "    for item in con_list:\n",
    "        # Make left and right into one list\n",
    "        left = [ch.lower() for ch in item.left if ch.isalpha()]\n",
    "        right = [ch.lower() for ch in item.right if ch.isalpha()]\n",
    "        combined = left + right\n",
    "        #combined = [w for w in (left + right) if w not in stopwords]\n",
    "        # Make freqDist, just in case\n",
    "        fd = nltk.FreqDist(combined)\n",
    "        sent_sum += sentiment(fd)\n",
    "        line_num += 1\n",
    "    if line_num == 0:\n",
    "        return None # Character had no appearences in chapter\n",
    "    return sent_sum / line_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae591c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming we have a list of the character names as we expect they appear\n",
    "# Assuming we have the chapters each book as .txt files\n",
    "char_list = [\"Harry\", \"Snape\", \"Voldemort\"] # List of character names as they appear\n",
    "\n",
    "# Assuming folder structure books/book_n/chapter_n.txt\n",
    "chapters = os.listdir(\"B7\")\n",
    "\n",
    "# Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "# tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "sentiment_by_character = []\n",
    "\n",
    "for character in char_list:\n",
    "    sentiments = []\n",
    "    for chapter in chapters:\n",
    "        f = open(\"B7/\" + chapter)\n",
    "        raw = f.read()\n",
    "        tokens = nltk.wordpunct_tokenize(raw)\n",
    "        text = nltk.Text(tokens)\n",
    "        con = text.concordance_list(character)\n",
    "        sentiments.append(con_sentiment(con))\n",
    "    sentiment_by_character.append((character, sentiments))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# https://stackoverflow.com/questions/4971269/how-to-pick-a-new-color-for-each-plotted-line-within-a-figure-in-matplotlib\n",
    "color = iter(cm.rainbow(np.linspace(0, 1, len(char_list))))\n",
    "\n",
    "for name, sentiments in sentiment_by_character:\n",
    "    c = next(color)\n",
    "    plt.plot(sentiments, c=c, label=name)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Chapter')\n",
    "plt.ylabel('Average sentiment')\n",
    "plt.title('Average sentiment by chapter for selected characters')\n",
    "plt.figtext(.5, -0.1, f\"Plot of the average sentiment for Harry, Snape, and Voldemort in Death Hallows when calculating sentiment from LabMT1.0.\", ha=\"center\")\n",
    "\n",
    "plt_labmt = plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ffb3e",
   "metadata": {},
   "source": [
    "## Sentiment for concordance of character, vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding sentiment from a concordance list\n",
    "def con_sentiment(con_list):\n",
    "    sent_sum = 0\n",
    "    line_num = 0\n",
    "    #for item in con_list:\n",
    "    # Make left and right into one list\n",
    "        #left = [ch.lower() for ch in item.left if ch.isalpha()]\n",
    "        #right = [ch.lower() for ch in item.right if ch.isalpha()]\n",
    "    combined = con_list.left + con_list.right\n",
    "    combined = \" \".join(combined)\n",
    "        #combined = [w for w in (left + right) if w not in stopwords]\n",
    "        # Make freqDist, just in case\n",
    "        #fd = nltk.FreqDist(combined)\n",
    "    vs = analyzer.polarity_scores(combined)\n",
    "        #print(vs[\"compound\"])\n",
    "        #print(combined)\n",
    "\n",
    "        #sent_sum += vs[\"compound\"]\n",
    "        #line_num += 1\n",
    "    if vs == 0:\n",
    "        return None # Character had no appearences in chapter\n",
    "    return vs[\"compound\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0f4d2",
   "metadata": {},
   "source": [
    "## LabMT1.0 vs vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233539c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b642a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sentiments for characters in a book \n",
    "\n",
    "# Input is a list of character names to look for as tokens\n",
    "# and a path to the chapters of the book\n",
    "def sent_chars_book(char_list, path_to_book):\n",
    "    chapters = os.listdir(path_to_book)\n",
    "\n",
    "    # Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "    # tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "    sentiment_by_character = []\n",
    "    \n",
    "    #print(f\"[sent_chars_book]: number of chapters found from path {path_to_book} = {len(chapters)}\")\n",
    "\n",
    "    for character in char_list:\n",
    "        sentiments = []\n",
    "        for chapter in chapters:\n",
    "            if \"replaced\" in chapter:\n",
    "                with open(path_to_book + chapter) as f:\n",
    "                    raw = f.read()\n",
    "                tokens = nltk.wordpunct_tokenize(raw)\n",
    "                text = nltk.Text(tokens)\n",
    "                cons = text.concordance_list(character)\n",
    "                sent_sum = 0\n",
    "                lines = 0\n",
    "                for con in cons:\n",
    "                    sent_sum += con_sentiment(con)\n",
    "                    lines += 1\n",
    "                if lines == 0:\n",
    "                    sentiments.append(None)\n",
    "                else: \n",
    "                    sentiments.append(sent_sum / lines)\n",
    "        sentiment_by_character.append((character, sentiments))\n",
    "    # Returns a list of the sentiments for that character for each chapter of that book\n",
    "    return sentiment_by_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38777194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all sentiments for characters from aliases in a book\n",
    "def sent_aliases_book(dict_aliases, path_to_book):\n",
    "    # Making the dict into a list of tuples (character, aliases)\n",
    "    character_aliases = list(dict_aliases.items())\n",
    "    chapters = os.listdir(path_to_book)\n",
    "\n",
    "    # Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "    # tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "    sentiment_by_character = []\n",
    "\n",
    "    for character, aliases in character_aliases: # For each list in the given list of lists\n",
    "        sentiments = []\n",
    "        for chapter in chapters: # For each chapter in the book\n",
    "            lines = 0\n",
    "            sent_sum = 0\n",
    "            \n",
    "            # read in the chapter\n",
    "            f = open(path_to_book + chapter)\n",
    "            raw = f.read()\n",
    "            tokens = nltk.wordpunct_tokenize(raw)\n",
    "            text = nltk.Text(tokens)\n",
    "                \n",
    "            for alias in aliases: # For each alias for that character\n",
    "\n",
    "                # Make a concordance list for that alias in that chapter\n",
    "                cons = text.concordance_list(alias)\n",
    "                \n",
    "                # Sum up the total sentiment for that alias and the number of lines it occurs in\n",
    "                for con in cons:\n",
    "                    sent_sum += con_sentiment(con)\n",
    "                    lines += 1\n",
    "            if lines == 0: # if none \n",
    "                sentiments.append(None)\n",
    "            else: \n",
    "                sentiments.append(sent_sum / lines)\n",
    "        sentiment_by_character.append((character, sentiments))\n",
    "    # Returns a list of tuples on the form (character name, list of sentiments)\n",
    "    return sentiment_by_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251e887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = dict({\"Harry Potter\": [\"Harry\"], \"Ron Weasley\": [\"Ron\"], \"Harry Ronner\": [\"Harry\", \"Ron\"]})\n",
    "sentiments = sent_chars_book([\"Harry_Potter\"], \"B7/\")\n",
    "plot_sentiments(sentiments, f\"Making a test\\ncan I make new lines?\")\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927935ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the sentiments for a list of characters\n",
    "# input is a list of lists, each list contains the sentiments by chapter/book\n",
    "# for each character. Designed to take input from either\n",
    "# sent_chars_book or sent_aliases_book\n",
    "def plot_sentiments(sentiment_by_character, figure_text, xs_vertical_lines):\n",
    "    # Init iterator\n",
    "    color = iter(cm.rainbow(np.linspace(0, 1, len(sentiment_by_character))))\n",
    "    plt.margins(x=0)\n",
    "    for name, sentiments in sentiment_by_character:\n",
    "        if (name == \"Gryffindor\"):\n",
    "            c = \"red\"\n",
    "            a = 0.5\n",
    "        elif (\"Slytherin\" in name):\n",
    "            c = \"green\"\n",
    "            a = 1\n",
    "        elif (name == \"Hufflepuff\"):\n",
    "            c = \"yellow\"\n",
    "            a = 1\n",
    "        elif (name == \"Ravenclaw\"):\n",
    "            c = \"blue\"\n",
    "            a = 1\n",
    "        else:\n",
    "            c = next(color)\n",
    "            a = 0.5\n",
    "        plt.plot(sentiments, c=c, alpha=a, label=name)\n",
    "    plt.axhline(y = 0.05, color =\"purple\", linestyle = '--')\n",
    "    plt.axhline(y = -0.05, color =\"purple\", linestyle = '--')\n",
    "    \n",
    "    for book, vertical_line in xs_vertical_lines:\n",
    "        plt.axvline(x = vertical_line, color = 'black')\n",
    "\n",
    "\n",
    "    #plt.legend()\n",
    "\n",
    "    plt.xlabel('Chapter')\n",
    "    plt.ylabel('Average sentiment')\n",
    "    #plt.title('Average sentiment by chapter for selected characters')\n",
    "    plt.figtext(.5, -0.1, figure_text, ha=\"center\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1bee0",
   "metadata": {},
   "source": [
    "# Sentiment for houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character tuple list\n",
    "import csv\n",
    "import os\n",
    "\n",
    "characters = []\n",
    "\n",
    "with open(\"HP_characters.csv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    csv = csv.reader(sent_file, delimiter=\",\")\n",
    "    for row in csv:\n",
    "        name = row[0].replace(' ', '_')\n",
    "        parentage = row[1]\n",
    "        house = row[2]\n",
    "        occupation = row[3]\n",
    "        characters.append((name, parentage, house, occupation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gryffindors = [n for n, p, h, o in characters if h == \"Gryffindor\"]\n",
    "hufflepuffs = [n for n, p, h, o in characters if h == \"Hufflepuff\"]\n",
    "ravenclaws = [n for n, p, h, o in characters if h == \"Ravenclaw\"]\n",
    "slytherins = [n for n, p, h, o in characters if h == \"Slytherin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b6ed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: An entitiy, e.g. a list of characters belonging to a house,\n",
    "#        all characters from the series etc. and the corresponding\n",
    "#        sentiments for them. May take output of sent_chars_book as\n",
    "#        input.\n",
    "# Output: A list of the average sentiments for the given entity \n",
    "\n",
    "def avgsent_entity(entity):\n",
    "    avgsent_entity = [0] * len(entity[0][1])\n",
    "    #print(f\"[avgsent_entity]: length of sentiment list for first char: {len(entity[0][1])}\")\n",
    "    for c in range(0,len(entity)):\n",
    "        for i in range(0, len(entity[c][1])):\n",
    "            if entity[c][1][i] is not None:\n",
    "                avgsent_entity[i] += entity[c][1][i]\n",
    "    for i in range(len(avgsent_entity)):\n",
    "        if avgsent_entity[i] == 0:\n",
    "            avgsent_entity[i] = None\n",
    "    return avgsent_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bd04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsent_gryffindor = []\n",
    "avgsent_hufflepuff = []\n",
    "avgsent_ravenclaw = []\n",
    "avgsent_slytherin = []\n",
    "for book in [\"B1/\" , \"B2/\", \"B3/\", \"B4/\", \"B5/\", \"B6/\", \"B7/\"]:\n",
    "    tmp_gryf = sent_chars_book(gryffindors, book)\n",
    "    tmp_huff = sent_chars_book(hufflepuffs, book)\n",
    "    tmp_rave = sent_chars_book(ravenclaws, book)\n",
    "    tmp_slyt = sent_chars_book(slytherins, book)\n",
    "    \n",
    "    avgsent_gryffindor += avgsent_entity(tmp_gryf)\n",
    "    avgsent_hufflepuff += avgsent_entity(tmp_huff)\n",
    "    avgsent_ravenclaw += avgsent_entity(tmp_rave)\n",
    "    avgsent_slytherin += avgsent_entity(tmp_slyt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34aea6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef14af3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182440f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsent_slytherin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaf4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avgsent_gryffindor = avgsent_house_B1(sent_gryffindors)\n",
    "#avgsent_hufflepuff = avgsent_house_B1(sent_hufflepuffs)\n",
    "#avgsent_ravenclaw = avgsent_house_B1(sent_ravenclaws)\n",
    "#avgsent_slytherin = avgsent_house_B1(sent_slytherins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e913a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d71261",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sent_list = [(\"Gryffindor\", avgsent_gryffindor), \n",
    "                 (\"Slytherin\", avgsent_slytherin),\n",
    "                 (\"Hufflepuff\", avgsent_hufflepuff),\n",
    "                 (\"Ravenclaw\", avgsent_ravenclaw)]\n",
    "xs_books = [(\"B1\", 17), (\"B2\", 34), (\"B3\", 56), (\"B4\", 93), (\"B5\", 131), (\"B6\", 161)]\n",
    "plot_sentiments(avg_sent_list, \"Average sentiment for the four houses throughout the books\", xs_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bef6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(avgsent_slytherin))\n",
    "print(len(avgsent_gryffindor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bb8bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dce76077",
   "metadata": {},
   "source": [
    "# Sentiment by chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8790f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sentiments for characters in a book \n",
    "\n",
    "# Input is a list of character names to look for as tokens\n",
    "# and a path to the chapters of the book\n",
    "def sent_book(path_to_book):\n",
    "    chapters = os.listdir(path_to_book)\n",
    "\n",
    "    # Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "    # tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "    sentiments_by_chapter = []\n",
    "    \n",
    "    for chapter in chapters:\n",
    "        if \"replaced\" in chapter:\n",
    "            with open(path_to_book + chapter) as f:\n",
    "                raw = f.read()\n",
    "            sentiments_by_chapter.append(analyzer.polarity_scores(raw)[\"compound\"])\n",
    "    # Returns a list of the sentiments for that character for each chapter of that book\n",
    "    return sentiments_by_chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd63bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_B1 = sent_book(\"B1/\")\n",
    "plot_sentiments([(\"Sentiment book1\", sent_B1)], \"Sentiment by chapter for book1\", [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dc207",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_sent = sent_B1\n",
    "series_sent += sent_book(\"B2/\")\n",
    "series_sent += sent_book(\"B3/\")\n",
    "series_sent += sent_book(\"B4/\")\n",
    "series_sent += sent_book(\"B5/\")\n",
    "series_sent += sent_book(\"B6/\")\n",
    "series_sent += sent_book(\"B7/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c400de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdafc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiments([(\"Sentiment for series\", series_sent)], \"Sentiment by chapter for entire series\", [(\"B1\", 17), (\"B2\", 34), (\"B3\", 56), (\"B4\", 93), (\"B5\", 131), (\"B6\", 161)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8965d1",
   "metadata": {},
   "source": [
    "# Average sentiment of all characters by chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef55ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_names = [n for n, i in characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c77fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sent_chars_book(char_list, path_to_book), with char_list as the\n",
    "# full list of characters and then iterate through each book\n",
    "avgsent_chars_series = []\n",
    "for book in [\"B1/\" , \"B2/\", \"B3/\", \"B4/\", \"B5/\", \"B6/\", \"B7/\"]:\n",
    "    tmp_series = sent_chars_book(character_names, book)\n",
    "    avgsent_chars_series += avgsent_entity(tmp_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee98e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiments([(\"Average sentiment of characters\", avgsent_chars_series)], \"Average sentiment of all characters by chapter for entire series\", [(\"B1\", 17), (\"B2\", 34), (\"B3\", 56), (\"B4\", 93), (\"B5\", 131), (\"B6\", 161)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a4b72f",
   "metadata": {},
   "source": [
    "# Average sentiment for house and sentiment for its students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7938814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_group_and_members(group, label_group, book_list):\n",
    "    sent_members = [(n, []) for n in group]\n",
    "    avgsent_ent = []\n",
    "    \n",
    "    for book in book_list:\n",
    "        tmp = sent_chars_book(group, book)\n",
    "        \n",
    "        avgsent_ent += avgsent_entity(tmp)\n",
    "        \n",
    "        for i in range (len(entity)):\n",
    "            sent_members[i] = (sent_members[i][0], sent_members[i][1]+tmp[i][1])\n",
    "            \n",
    "    return [(label_entity, avgsent_ent)] + sent_members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94049c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_slytherins = [(n, []) for n in slytherins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsent_slytherin = []\n",
    "for book in [\"B1/\" , \"B2/\", \"B3/\", \"B4/\", \"B5/\", \"B6/\", \"B7/\"]:\n",
    "    tmp_slyt = sent_chars_book(slytherins, book)\n",
    "    \n",
    "    avgsent_slytherin += avgsent_entity(tmp_slyt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "for book in [\"B1/\", \"B2/\", \"B3/\", \"B4/\", \"B5/\", \"B6/\", \"B7/\"]:\n",
    "    tmp = sent_chars_book(slytherins, book)\n",
    "    for i in range (len(sent_slytherins)):\n",
    "        sent_slytherins[i] = (sent_slytherins[i][0], sent_slytherins[i][1]+tmp[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f9a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list = [\"B1/\", \"B2/\", \"B3/\", \"B4/\", \"B5/\", \"B6/\", \"B7/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [(\"Slytherin average\", avgsent_slytherin)] + sent_slytherins\n",
    "#sents = sent_slytherins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107866fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_label = \"Slytherins\"\n",
    "sents = sent_entity_and_members(slytherins, entity_label, book_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e800069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d0fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiments(sents, \"Average sentiments for Slytherins, and sentimens for all Slytherins\", [(\"B1\", 17), (\"B2\", 34), (\"B3\", 56), (\"B4\", 93), (\"B5\", 131), (\"B6\", 161)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
