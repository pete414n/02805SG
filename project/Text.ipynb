{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce307b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import csv\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from community import community_louvain\n",
    "from fa2 import ForceAtlas2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b56336",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    ">We want to be able to analyse the sentiment of a character throughout the books. Our idea for achieving this is to use concordance from nltk with the character name, this way we will get all of the context surrounding a character. For each of these occurrences we can compute the sentiment for the context, and use that sentiment as a representative for the character. This could be done on occurence basis, but since we are expecting to have many occurences how harry, and fewer for other main characters, and even less for the remaining characters, this would require additional steps to normalize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5816beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chapter in os.listdir(\"B7/\"):\n",
    "    f = open(\"B7/\" + chapter)\n",
    "    raw = f.read()\n",
    "    tokens += nltk.wordpunct_tokenize(raw)\n",
    "text = nltk.Text(tokens)\n",
    "\n",
    "text.dispersion_plot([\"Harry\", \"Voldemort\", \"Snape\", \"Luna\", \"Neville\", \"Nagini\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd021b74",
   "metadata": {},
   "source": [
    "##  Sentiment for concordance of character, LabMT1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "\n",
    "# Get characters and communities, according to fandom graph\n",
    "with open(\"communities_from_fandom.csv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    csv = csv.reader(sent_file, delimiter=\",\")\n",
    "    for row in csv:\n",
    "        name = row[0]\n",
    "        community = row[1]\n",
    "        characters.append((name, community))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Create an empty list to store tuples of words and their \n",
    "# average happiness score\n",
    "sent_list = []\n",
    "\n",
    "# Read in the .tsv file\n",
    "with open(\"LabMT1.0.tsv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    tsv_reader = csv.DictReader(sent_file, delimiter=\"\\t\")\n",
    "    # For each sentiment in the file, save the word and average happiness in a tuple\n",
    "    # and add it to the list\n",
    "    for sent in tsv_reader:\n",
    "        word = sent[\"word\"]\n",
    "        average = sent[\"happiness_average\"]\n",
    "        sent_list.append((word, average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cceb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to calculate sentiment for a list of tokens\n",
    "# Function for calculating the sentiment of a file from the frequency distribution for that file\n",
    "def sentiment(tokens):\n",
    "    # Total sentiment score of file\n",
    "    sent_sum = 0.0\n",
    "    # Total number of occurences of words\n",
    "    occ_sum = 0\n",
    "    \n",
    "    # For each token and associated number of occurences\n",
    "    for token, occ in tokens.items():\n",
    "        # If the token is in the given list of words with rated happiness\n",
    "        for word, score in sent_list:\n",
    "            if token == word:\n",
    "                sent_sum += (float(score) * occ)\n",
    "                occ_sum += occ\n",
    "    return sent_sum / occ_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b7416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding sentiment from a concordance list\n",
    "def con_sentiment(con_list):\n",
    "    sent_sum = 0\n",
    "    line_num = 0\n",
    "    for item in con_list:\n",
    "        # Make left and right into one list\n",
    "        left = [ch.lower() for ch in item.left if ch.isalpha()]\n",
    "        right = [ch.lower() for ch in item.right if ch.isalpha()]\n",
    "        combined = left + right\n",
    "        #combined = [w for w in (left + right) if w not in stopwords]\n",
    "        # Make freqDist, just in case\n",
    "        fd = nltk.FreqDist(combined)\n",
    "        sent_sum += sentiment(fd)\n",
    "        line_num += 1\n",
    "    if line_num == 0:\n",
    "        return None # Character had no appearences in chapter\n",
    "    return sent_sum / line_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae591c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming we have a list of the character names as we expect they appear\n",
    "# Assuming we have the chapters each book as .txt files\n",
    "char_list = [\"Harry\", \"Dumbledore\"] # List of character names as they appear\n",
    "\n",
    "# Assuming folder structure books/book_n/chapter_n.txt\n",
    "chapters = os.listdir(\"B7\")\n",
    "\n",
    "# Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "# tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "sentiment_by_character = []\n",
    "\n",
    "for character in char_list:\n",
    "    sentiments = []\n",
    "    for chapter in chapters:\n",
    "        f = open(\"B7/\" + chapter)\n",
    "        raw = f.read()\n",
    "        tokens = nltk.wordpunct_tokenize(raw)\n",
    "        text = nltk.Text(tokens)\n",
    "        con = text.concordance_list(character)\n",
    "        sentiments.append(con_sentiment(con))\n",
    "    sentiment_by_character.append((character, sentiments))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# https://stackoverflow.com/questions/4971269/how-to-pick-a-new-color-for-each-plotted-line-within-a-figure-in-matplotlib\n",
    "color = iter(cm.rainbow(np.linspace(0, 1, len(char_list))))\n",
    "\n",
    "# If a character does not appear in a chapter, the sentiment becomes 0. \n",
    "# To mitigate this, we set these chapters to have the sentiment of the previous\n",
    "# otherwise these 0 drowns a lot of the difference\n",
    "\n",
    "for name, sentiments in sentiment_by_character:\n",
    "    c = next(color)\n",
    "    plt.plot(sentiments, c=c, label=name)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#print(sentiment_by_character)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ffb3e",
   "metadata": {},
   "source": [
    "## Sentiment for concordance of character, vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding sentiment from a concordance list\n",
    "def con_sentiment(con_list):\n",
    "    sent_sum = 0\n",
    "    line_num = 0\n",
    "    #for item in con_list:\n",
    "    # Make left and right into one list\n",
    "        #left = [ch.lower() for ch in item.left if ch.isalpha()]\n",
    "        #right = [ch.lower() for ch in item.right if ch.isalpha()]\n",
    "    combined = con_list.left + con_list.right\n",
    "    combined = \" \".join(combined)\n",
    "        #combined = [w for w in (left + right) if w not in stopwords]\n",
    "        # Make freqDist, just in case\n",
    "        #fd = nltk.FreqDist(combined)\n",
    "    vs = analyzer.polarity_scores(combined)\n",
    "        #print(vs[\"compound\"])\n",
    "        #print(combined)\n",
    "\n",
    "        #sent_sum += vs[\"compound\"]\n",
    "        #line_num += 1\n",
    "    if vs == 0:\n",
    "        return None # Character had no appearences in chapter\n",
    "    return vs[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For single chapter\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Assuming we have a list of the character names as we expect they appear\n",
    "# Assuming we have the chapters each book as .txt files\n",
    "char_list = [\"Harry\", \"Snape\", \"Voldemort\"] # List of character names as they appear\n",
    "\n",
    "# Assuming folder structure books/book_n/chapter_n.txt\n",
    "chapters = os.listdir(\"B7\")\n",
    "\n",
    "# Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "# tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "sentiment_by_character = []\n",
    "\n",
    "for character in char_list:\n",
    "    sentiments = []\n",
    "    for chapter in chapters:\n",
    "        f = open(\"B7/\" + chapter)\n",
    "        raw = f.read()\n",
    "        tokens = nltk.wordpunct_tokenize(raw)\n",
    "        text = nltk.Text(tokens)\n",
    "        cons = text.concordance_list(character)\n",
    "        sent_sum = 0\n",
    "        lines = 0\n",
    "        for con in cons:\n",
    "            sent_sum += con_sentiment(con)\n",
    "            lines += 1\n",
    "        if lines == 0:\n",
    "            sentiments.append(None)\n",
    "        else: \n",
    "            sentiments.append(sent_sum / lines)\n",
    "    sentiment_by_character.append((character, sentiments))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# https://stackoverflow.com/questions/4971269/how-to-pick-a-new-color-for-each-plotted-line-within-a-figure-in-matplotlib\n",
    "color = iter(cm.rainbow(np.linspace(0, 1, len(char_list))))\n",
    "\n",
    "# If a character does not appear in a chapter, the sentiment becomes 0. \n",
    "# To mitigate this, we set these chapters to have the sentiment of the previous\n",
    "# otherwise these 0 drowns a lot of the difference\n",
    "#for character, sentiment in sentiment_by_character:\n",
    "#    for i in range(len(chapters)):\n",
    "#        if sentiment == 0:\n",
    "            \n",
    "# Missing value i stedet for at sætte til 0 eller sidste værdi\n",
    "\n",
    "for name, sentiments in sentiment_by_character:\n",
    "    c = next(color)\n",
    "    plt.plot(sentiments, c=c, label=name)\n",
    "plt.axhline(y = 0.05, color =\"purple\", linestyle = '--')\n",
    "plt.axhline(y = -0.05, color =\"purple\", linestyle = '--')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#print(sentiment_by_character)\n",
    "\n",
    "#print(sentiment_by_character)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
