{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce307b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import csv\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from community import community_louvain\n",
    "from fa2 import ForceAtlas2\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b56336",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    ">We want to be able to analyse the sentiment of a character throughout the books. Our idea for achieving this is to use concordance from nltk with the character name, this way we will get all of the context surrounding a character. For each of these occurrences we can compute the sentiment for the context, and use that sentiment as a representative for the character. This could be done on occurence basis, but since we are expecting to have many occurences how harry, and fewer for other main characters, and even less for the remaining characters, this would require additional steps to normalize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5816beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for chapter in os.listdir(\"B7/\"):\n",
    "    f = open(\"B7/\" + chapter)\n",
    "    raw = f.read()\n",
    "    tokens += nltk.wordpunct_tokenize(raw)\n",
    "text = nltk.Text(tokens)\n",
    "\n",
    "text.dispersion_plot([\"Harry\", \"Voldemort\", \"Snape\", \"Luna\", \"Neville\", \"Nagini\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd021b74",
   "metadata": {},
   "source": [
    "##  Sentiment for concordance of character, LabMT1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = []\n",
    "\n",
    "# Get characters and communities, according to fandom graph\n",
    "with open(\"communities_from_fandom.csv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    csv = csv.reader(sent_file, delimiter=\",\")\n",
    "    for row in csv:\n",
    "        name = row[0]\n",
    "        community = row[1]\n",
    "        characters.append((name, community))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "# Create an empty list to store tuples of words and their \n",
    "# average happiness score\n",
    "sent_list = []\n",
    "\n",
    "# Read in the .tsv file\n",
    "with open(\"LabMT1.0.tsv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    tsv_reader = csv.DictReader(sent_file, delimiter=\"\\t\")\n",
    "    # For each sentiment in the file, save the word and average happiness in a tuple\n",
    "    # and add it to the list\n",
    "    for sent in tsv_reader:\n",
    "        word = sent[\"word\"]\n",
    "        average = sent[\"happiness_average\"]\n",
    "        sent_list.append((word, average))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cceb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to calculate sentiment for a list of tokens\n",
    "# Function for calculating the sentiment of a file from the frequency distribution for that file\n",
    "def sentiment(tokens):\n",
    "    # Total sentiment score of file\n",
    "    sent_sum = 0.0\n",
    "    # Total number of occurences of words\n",
    "    occ_sum = 0\n",
    "    \n",
    "    # For each token and associated number of occurences\n",
    "    for token, occ in tokens.items():\n",
    "        # If the token is in the given list of words with rated happiness\n",
    "        for word, score in sent_list:\n",
    "            if token == word:\n",
    "                sent_sum += (float(score) * occ)\n",
    "                occ_sum += occ\n",
    "    return sent_sum / occ_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b7416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding sentiment from a concordance list\n",
    "def con_sentiment(con_list):\n",
    "    sent_sum = 0\n",
    "    line_num = 0\n",
    "    for item in con_list:\n",
    "        # Make left and right into one list\n",
    "        left = [ch.lower() for ch in item.left if ch.isalpha()]\n",
    "        right = [ch.lower() for ch in item.right if ch.isalpha()]\n",
    "        combined = left + right\n",
    "        #combined = [w for w in (left + right) if w not in stopwords]\n",
    "        # Make freqDist, just in case\n",
    "        fd = nltk.FreqDist(combined)\n",
    "        sent_sum += sentiment(fd)\n",
    "        line_num += 1\n",
    "    if line_num == 0:\n",
    "        return None # Character had no appearences in chapter\n",
    "    return sent_sum / line_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2ccfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae591c4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming we have a list of the character names as we expect they appear\n",
    "# Assuming we have the chapters each book as .txt files\n",
    "char_list = [\"Harry\", \"Snape\", \"Voldemort\"] # List of character names as they appear\n",
    "\n",
    "# Assuming folder structure books/book_n/chapter_n.txt\n",
    "chapters = os.listdir(\"B7\")\n",
    "\n",
    "# Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "# tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "sentiment_by_character = []\n",
    "\n",
    "for character in char_list:\n",
    "    sentiments = []\n",
    "    for chapter in chapters:\n",
    "        f = open(\"B7/\" + chapter)\n",
    "        raw = f.read()\n",
    "        tokens = nltk.wordpunct_tokenize(raw)\n",
    "        text = nltk.Text(tokens)\n",
    "        con = text.concordance_list(character)\n",
    "        sentiments.append(con_sentiment(con))\n",
    "    sentiment_by_character.append((character, sentiments))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# https://stackoverflow.com/questions/4971269/how-to-pick-a-new-color-for-each-plotted-line-within-a-figure-in-matplotlib\n",
    "color = iter(cm.rainbow(np.linspace(0, 1, len(char_list))))\n",
    "\n",
    "for name, sentiments in sentiment_by_character:\n",
    "    c = next(color)\n",
    "    plt.plot(sentiments, c=c, label=name)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Chapter')\n",
    "plt.ylabel('Average sentiment')\n",
    "plt.title('Average sentiment by chapter for selected characters')\n",
    "plt.figtext(.5, -0.1, f\"Plot of the average sentiment for Harry, Snape, and Voldemort in Death Hallows when calculating sentiment from LabMT1.0.\", ha=\"center\")\n",
    "\n",
    "plt_labmt = plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ffb3e",
   "metadata": {},
   "source": [
    "## Sentiment for concordance of character, vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding sentiment from a concordance list\n",
    "def con_sentiment(con_list):\n",
    "    sent_sum = 0\n",
    "    line_num = 0\n",
    "    #for item in con_list:\n",
    "    # Make left and right into one list\n",
    "        #left = [ch.lower() for ch in item.left if ch.isalpha()]\n",
    "        #right = [ch.lower() for ch in item.right if ch.isalpha()]\n",
    "    combined = con_list.left + con_list.right\n",
    "    combined = \" \".join(combined)\n",
    "        #combined = [w for w in (left + right) if w not in stopwords]\n",
    "        # Make freqDist, just in case\n",
    "        #fd = nltk.FreqDist(combined)\n",
    "    vs = analyzer.polarity_scores(combined)\n",
    "        #print(vs[\"compound\"])\n",
    "        #print(combined)\n",
    "\n",
    "        #sent_sum += vs[\"compound\"]\n",
    "        #line_num += 1\n",
    "    if vs == 0:\n",
    "        return None # Character had no appearences in chapter\n",
    "    return vs[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7d612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For single chapter\n",
    "\n",
    "\n",
    "\n",
    "# Assuming we have a list of the character names as we expect they appear\n",
    "# Assuming we have the chapters each book as .txt files\n",
    "char_list = [\"Harry\", \"Snape\", \"Voldemort\"] # List of character names as they appear\n",
    "\n",
    "# Assuming folder structure books/book_n/chapter_n.txt\n",
    "chapters = os.listdir(\"B7\")\n",
    "\n",
    "# Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "# tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "sentiment_by_character = []\n",
    "\n",
    "for character in char_list:\n",
    "    sentiments = []\n",
    "    for chapter in chapters:\n",
    "        f = open(\"B7/\" + chapter)\n",
    "        raw = f.read()\n",
    "        tokens = nltk.wordpunct_tokenize(raw)\n",
    "        text = nltk.Text(tokens)\n",
    "        cons = text.concordance_list(character)\n",
    "        sent_sum = 0\n",
    "        lines = 0\n",
    "        for con in cons:\n",
    "            sent_sum += con_sentiment(con)\n",
    "            lines += 1\n",
    "        if lines == 0:\n",
    "            sentiments.append(None)\n",
    "        else: \n",
    "            sentiments.append(sent_sum / lines)\n",
    "    sentiment_by_character.append((character, sentiments))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.50, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "# https://stackoverflow.com/questions/4971269/how-to-pick-a-new-color-for-each-plotted-line-within-a-figure-in-matplotlib\n",
    "color = iter(cm.rainbow(np.linspace(0, 1, len(char_list))))\n",
    "\n",
    "# If a character does not appear in a chapter, the sentiment becomes 0. \n",
    "# To mitigate this, we set these chapters to have the sentiment of the previous\n",
    "# otherwise these 0 drowns a lot of the difference\n",
    "#for character, sentiment in sentiment_by_character:\n",
    "#    for i in range(len(chapters)):\n",
    "#        if sentiment == 0:\n",
    "            \n",
    "# Missing value i stedet for at sætte til 0 eller sidste værdi\n",
    "\n",
    "for name, sentiments in sentiment_by_character:\n",
    "    c = next(color)\n",
    "    plt.plot(sentiments, c=c, label=name)\n",
    "plt.axhline(y = 0.05, color =\"purple\", linestyle = '--')\n",
    "plt.axhline(y = -0.05, color =\"purple\", linestyle = '--')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('Chapter')\n",
    "plt.ylabel('Average sentiment')\n",
    "plt.title('Average sentiment by chapter for selected characters')\n",
    "plt.figtext(.5, -0.1, f\"Plot of the average sentiment for Harry, Snape, and Voldemort in Death Hallows when using vaderSentiment.\", ha=\"center\")\n",
    "\n",
    "plt_vader = plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0f4d2",
   "metadata": {},
   "source": [
    "## LabMT1.0 vs vaderSentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233539c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b642a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sentiments for characters in a book \n",
    "\n",
    "# Input is a list of character names to look for as tokens\n",
    "# and a path to the chapters of the book\n",
    "def sent_chars_book(char_list, path_to_book):\n",
    "    chapters = os.listdir(path_to_book)\n",
    "\n",
    "    # Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "    # tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "    sentiment_by_character = []\n",
    "\n",
    "    for character in char_list:\n",
    "        sentiments = []\n",
    "        for chapter in chapters:\n",
    "            f = open(path_to_book + chapter)\n",
    "            raw = f.read()\n",
    "            tokens = nltk.wordpunct_tokenize(raw)\n",
    "            text = nltk.Text(tokens)\n",
    "            cons = text.concordance_list(character)\n",
    "            sent_sum = 0\n",
    "            lines = 0\n",
    "            for con in cons:\n",
    "                sent_sum += con_sentiment(con)\n",
    "                lines += 1\n",
    "            if lines == 0:\n",
    "                sentiments.append(None)\n",
    "            else: \n",
    "                sentiments.append(sent_sum / lines)\n",
    "        sentiment_by_character.append((character, sentiments))\n",
    "    # Returns a list of the sentiments for that character for each chapter of that book\n",
    "    return sentiment_by_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38777194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all sentiments for characters from aliases in a book\n",
    "def sent_aliases_book(dict_aliases, path_to_book):\n",
    "    # Making the dict into a list of tuples (character, aliases)\n",
    "    character_aliases = list(dict_aliases.items())\n",
    "    chapters = os.listdir(path_to_book)\n",
    "\n",
    "    # Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "    # tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "    sentiment_by_character = []\n",
    "\n",
    "    for character, aliases in character_aliases: # For each list in the given list of lists\n",
    "        sentiments = []\n",
    "        for chapter in chapters: # For each chapter in the book\n",
    "            lines = 0\n",
    "            sent_sum = 0\n",
    "            \n",
    "            # read in the chapter\n",
    "            f = open(path_to_book + chapter)\n",
    "            raw = f.read()\n",
    "            tokens = nltk.wordpunct_tokenize(raw)\n",
    "            text = nltk.Text(tokens)\n",
    "                \n",
    "            for alias in aliases: # For each alias for that character\n",
    "\n",
    "                # Make a concordance list for that alias in that chapter\n",
    "                cons = text.concordance_list(alias)\n",
    "                \n",
    "                # Sum up the total sentiment for that alias and the number of lines it occurs in\n",
    "                for con in cons:\n",
    "                    sent_sum += con_sentiment(con)\n",
    "                    lines += 1\n",
    "            if lines == 0: # if none \n",
    "                sentiments.append(None)\n",
    "            else: \n",
    "                sentiments.append(sent_sum / lines)\n",
    "        sentiment_by_character.append((character, sentiments))\n",
    "    # Returns a list of tuples on the form (character name, list of sentiments)\n",
    "    return sentiment_by_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict({\"Harry Potter\": [\"Harry\"], \"Ron Weasley\": [\"Ron\"], \"Harry Ronner\": [\"Harry\", \"Ron\"]})\n",
    "sentiments = sent_aliases_book(d, \"B7/\")\n",
    "plot_sentiments(sentiments, f\"Making a test\\ncan I make new lines?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927935ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the sentiments for a list of characters\n",
    "# input is a list of lists, each list contains the sentiments by chapter/book\n",
    "# for each character. Designed to take input from either\n",
    "# sent_chars_book or sent_aliases_book\n",
    "def plot_sentiments(sentiment_by_character, figure_text):\n",
    "    # Init iterator\n",
    "    color = iter(cm.rainbow(np.linspace(0, 1, len(sentiment_by_character))))\n",
    "\n",
    "    for name, sentiments in sentiment_by_character:\n",
    "        c = next(color)\n",
    "        plt.plot(sentiments, c=c, label=name)\n",
    "    plt.axhline(y = 0.05, color =\"purple\", linestyle = '--')\n",
    "    plt.axhline(y = -0.05, color =\"purple\", linestyle = '--')\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlabel('Chapter')\n",
    "    plt.ylabel('Average sentiment')\n",
    "    plt.title('Average sentiment by chapter for selected characters')\n",
    "    plt.figtext(.5, -0.1, figure_text, ha=\"center\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73356f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
