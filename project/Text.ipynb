{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce307b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import csv\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from community import community_louvain\n",
    "from fa2 import ForceAtlas2\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e861009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To achieve default \n",
    "average_length_of_sentence = 114 # Set this to 79\n",
    "sentences_for_con = 3 # And this to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b56336",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    ">We want to be able to analyse the sentiment of a character throughout the books. Our idea for achieving this is to use concordance from nltk with the character name, this way we will get all of the context surrounding a character. For each of these occurrences we can compute the sentiment for the context, and use that sentiment as a representative for the character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5816beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does not belong here, maybe usufull for arguing about normalizing harry potter weights in graphs?\n",
    "tokens = []\n",
    "for chapter in os.listdir(\"B7/\"):\n",
    "    if \"replaced\" in chapter:\n",
    "        f = open(\"B7/\" + chapter)\n",
    "        raw = f.read()\n",
    "        tokens += nltk.word_tokenize(raw)\n",
    "text = nltk.Text(tokens)\n",
    "\n",
    "text.dispersion_plot([\"Harry_Potter\", \"Tom_Riddle\", \"Severus_Snape\", \"Luna_Lovegood\", \"Neville_Longbottom\", \"Nagini\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09a42dd",
   "metadata": {},
   "source": [
    "## Sentiment calculations from LabMT1.0 vs VADER-Sentiment\n",
    ">We have considered two options for calculating our sentiment. Either we could use the the LabMT1.0 data set to find the sentiment of a portion of text by assigning each word in that text a value based on LabMT1.0, and then taking the average of those words. Or we could use <a href=\"https://github.com/cjhutto/vaderSentiment/blob/master/README.rst\">VADER-Sentiment</a>. We wanted to experiment with the VADER solution, since our initial findings for sentiment using LabMT1.0 had very similar values around 5.5. To experiment we have made a graph of sentiments for each chapter of Book 7, for Harry Potter, Voldemort, and Snape for both methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd021b74",
   "metadata": {},
   "source": [
    "###  Sentiment for concordance of character, LabMT1.0\n",
    "> First we create a list of tuples containing each word and the average happiness for that word. This allows us to go through a portion of text and look up the average happiness for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store tuples of words and their \n",
    "# average happiness score\n",
    "sent_list_labmt10 = []\n",
    "\n",
    "# Read in the .tsv file\n",
    "with open(\"LabMT1.0.tsv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    tsv_reader = csv.DictReader(sent_file, delimiter=\"\\t\")\n",
    "    # For each sentiment in the file, save the word and average happiness in a tuple\n",
    "    # and add it to the list\n",
    "    for sent in tsv_reader:\n",
    "        word = sent[\"word\"]\n",
    "        average = sent[\"happiness_average\"]\n",
    "        sent_list_labmt10.append((word, average))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11980e15",
   "metadata": {},
   "source": [
    ">We now define a function to calculate the average sentiment for a set of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cceb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to calculate sentiment for a list of tokens\n",
    "# Function for calculating the sentiment of a file from the frequency distribution for that file\n",
    "def sentiment_labmt10(tokens):\n",
    "    # Total sentiment score of file\n",
    "    sent_sum_labmt10 = 0.0\n",
    "    # Total number of occurences of words\n",
    "    occ_sum_labmt10 = 0\n",
    "    \n",
    "    # For each token and associated number of occurences\n",
    "    for token, occ in tokens.items():\n",
    "        # If the token is in the given list of words with rated happiness\n",
    "        for word, score in sent_list_labmt10:\n",
    "            if token == word:\n",
    "                sent_sum_labmt10 += (float(score) * occ)\n",
    "                occ_sum_labmt10 += occ\n",
    "    return sent_sum_labmt10 / occ_sum_labmt10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b62477",
   "metadata": {},
   "source": [
    ">And a function to calculate the sentiment for a concordance list found by nltk, and define a list of stopwords to be filtered out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323544a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_labmt10 = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b7416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding sentiment from a concordance list\n",
    "def con_sentiment_labmt10(con_list):\n",
    "    sent_sum = 0\n",
    "    line_num = 0\n",
    "    for item in con_list:\n",
    "        left = [ch.lower() for ch in item.left if ch.isalpha()]\n",
    "        right = [ch.lower() for ch in item.right if ch.isalpha()]\n",
    "        # Make left and right into one list and remove stopwords\n",
    "        combined = [w for w in (left + right) if w not in stopwords_labmt10]\n",
    "        \n",
    "        # Make frequency distribution \n",
    "        fd = nltk.FreqDist(combined)\n",
    "        sent_sum += sentiment_labmt10(fd)\n",
    "        line_num += 1\n",
    "    if line_num == 0:\n",
    "        return None # Character had no appearences in chapter\n",
    "    return sent_sum / line_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f429f44b",
   "metadata": {},
   "source": [
    ">We then run our test as described previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae591c4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define character list with the three characteres\n",
    "char_list_labmt10 = [\"Harry_Potter\", \"Severus_Snape\", \"Tom_Riddle\"] \n",
    "\n",
    "# Create a list of the chapters of book 7\n",
    "chapters_labmt10 = os.listdir(\"B7\")\n",
    "\n",
    "# Init a list to tuples (chraracter, [sentiments for each chapter for that character])\n",
    "sentiment_by_character_labmt10 = []\n",
    "\n",
    "# For each of the characters\n",
    "for character in char_list_labmt10:\n",
    "    sentiments = []\n",
    "    # For each chapter\n",
    "    for chapter in chapters_labmt10:\n",
    "        # Read in and tokenize the chapter\n",
    "        if \"replaced\" in chapter:\n",
    "            with open(\"B7/\" + chapter) as f:\n",
    "                    raw = f.read()\n",
    "            tokens = nltk.word_tokenize(raw)\n",
    "            text = nltk.Text(tokens)\n",
    "        \n",
    "            # Make concordance for that character\n",
    "            con = text.concordance_list(character, width = setences_for_con * average_length_of_sentence)\n",
    "        \n",
    "            # Calculate sentiments and append to the list for that character\n",
    "            sentiments.append(con_sentiment_labmt10(con))\n",
    "    # Append the character with its full sentiment list\n",
    "    sentiment_by_character_labmt10.append((character, sentiments))\n",
    "\n",
    "# https://stackoverflow.com/questions/4971269/how-to-pick-a-new-color-for-each-plotted-line-within-a-figure-in-matplotlib\n",
    "color = iter(cm.rainbow(np.linspace(0, 1, len(char_list_labmt10))))\n",
    "\n",
    "for name, sentiments in sentiment_by_character_labmt10:\n",
    "    c = next(color)\n",
    "    plt.plot(sentiments, c=c, label=name)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Chapter')\n",
    "plt.ylabel('Average sentiment')\n",
    "plt.title('Average sentiment by chapter for selected characters')\n",
    "plt.figtext(.5, -0.1, f\"Plot of the average sentiment for Harry, Snape, and Voldemort in book 7 when calculating sentiment from LabMT1.0.\", ha=\"center\")\n",
    "\n",
    "plt_labmt = plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ffb3e",
   "metadata": {},
   "source": [
    "### Sentiment for concordance of character, vaderSentiment\n",
    ">For VADER we use the same approach and code, but we have to redefine how we calculate sentiment from concordance, since we just have to pass a string to the analyzer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523deb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding sentiment from a concordance list\n",
    "def con_sentiment(con):\n",
    "    sent_sum = 0\n",
    "    line_num = 0\n",
    "    combined = con.left + con.right\n",
    "    combined = \" \".join(combined)\n",
    "\n",
    "    vs = analyzer.polarity_scores(combined)\n",
    "\n",
    "    if vs == 0:\n",
    "        return None # Character had no appearences in chapter\n",
    "    return vs[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0de875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define character list with the three characteres\n",
    "char_list_vader = [\"Harry_Potter\", \"Severus_Snape\", \"Tom_Riddle\"] \n",
    "\n",
    "# Create a list of the chapters of book 7\n",
    "chapters_vader = os.listdir(\"B7\")\n",
    "\n",
    "# Init a list to tuples (chraracter, [sentiments for each chapter for that character])\n",
    "sentiment_by_character_vader  = []\n",
    "\n",
    "# For each of the characters\n",
    "for character in char_list_vader :\n",
    "    sentiments = []\n",
    "    for chapter in chapters_vader :\n",
    "        if \"replaced\" in chapter:\n",
    "            with open(\"B7/\" + chapter) as f:\n",
    "                    raw = f.read()\n",
    "            tokens = nltk.word_tokenize(raw)\n",
    "            text = nltk.Text(tokens)\n",
    "            cons = text.concordance_list(character, width = setences_for_con * average_length_of_sentence)\n",
    "            sent_sum = 0\n",
    "            lines = 0\n",
    "            for con in cons:\n",
    "                sent_sum += con_sentiment(con)\n",
    "                lines += 1\n",
    "            if lines == 0:\n",
    "                sentiments.append(None)\n",
    "            else: \n",
    "                sentiments.append(sent_sum / lines)\n",
    "    sentiment_by_character_vader .append((character, sentiments))\n",
    "\n",
    "# https://stackoverflow.com/questions/4971269/how-to-pick-a-new-color-for-each-plotted-line-within-a-figure-in-matplotlib\n",
    "color_vader  = iter(cm.rainbow(np.linspace(0, 1, len(char_list_vader ))))\n",
    "\n",
    "for name, sentiments in sentiment_by_character_vader :\n",
    "    c = next(color_vader)\n",
    "    plt.plot(sentiments, c=c, label=name)\n",
    "\n",
    "plt.axhline(y = 0.05, color =\"purple\", linestyle = '--', label=\"Neutral region\")\n",
    "plt.axhline(y = -0.05, color =\"purple\", linestyle = '--')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Chapter')\n",
    "plt.ylabel('Average sentiment')\n",
    "plt.title('Average sentiment by chapter for selected characters')\n",
    "plt.figtext(.5, -0.1, f\"Plot of the average sentiment for Harry, Snape, and Voldemort in book 7 when calculating sentiment with VADER.\", ha=\"center\")\n",
    "\n",
    "plt_vader = plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b0f4d2",
   "metadata": {},
   "source": [
    "### Conclusion: LabMT1.0 vs vaderSentiment\n",
    ">Both results are similar, but we see an advantage in using VADER when we consider the sentiment for Harry Potter. Looking at the graphs we can see that there are similar trends for Harry throughout the book, but with VADER the sentiment becomes more consistent, in that it appears to be in the neutral region at some points, and then go out of it. On the other hand the MatLab1.0 seems to indicate that Harry is well above 5.1 throughout the book, which we would consider to be above neutral. Based on this preliminary test we believe that we will get a more clear picture from VADER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d233539c",
   "metadata": {},
   "source": [
    "## Functions for calculating sentiment\n",
    ">The following section contains various functions we have defined to find and plot sentiment for various cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cbf3ef",
   "metadata": {},
   "source": [
    "### ```sent_chars_book(char_list, path_to_book)```\n",
    ">The function takes a list of character names and a path to a book. It computes the average sentiment of each character in the list throughout the book on a chapter basis. This can be used to find out how the sentiment of a single character changes throughout a book or a group of characters such as a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b642a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: A list of character names to look for as tokens\n",
    "        and a path to the chapters of the book\n",
    "Output: A list of tuples, with the character name and a list\n",
    "        of the sentiments for each chapter for that character\n",
    "\"\"\"\n",
    "def sent_chars_book_list(char_list, book_list, sentences):\n",
    "    # Init list to hold tuples\n",
    "    sentiment_of_character = [(n, []) for n in char_list]\n",
    "    #print(sentiment_of_character)\n",
    "    #print(len(sentiment_of_character))\n",
    "    #print(char_list)\n",
    "    \n",
    "    chapter_counter = 0\n",
    "    for book in book_list:\n",
    "        \n",
    "        # For each chapter\n",
    "        for chapter in os.listdir(book):\n",
    "            if \"replaced\" in chapter:\n",
    "                # Read in the chapter and tokenize\n",
    "                with open(book + chapter) as f:\n",
    "                    raw = f.read()\n",
    "                tokens = nltk.word_tokenize(raw)\n",
    "                text = nltk.Text(tokens)\n",
    "\n",
    "                character_counter = 0\n",
    "                # For each character in the given list\n",
    "                for character in char_list:\n",
    "                    # Make concordance for that character in that chapter\n",
    "                    cons = text.concordance_list(character, width = sentences * average_length_of_sentence)\n",
    "                    #print(character)\n",
    "                    #print(f\"character = {character}, sentiment_of_character[{character_counter}] = {sentiment_of_character[character_counter]}\")\n",
    "\n",
    "                    sent_sum = 0\n",
    "                    lines = 0\n",
    "                    # For each concordance line\n",
    "                    for con in cons:\n",
    "                        # Calculate the sentiment for that concordance line\n",
    "                        sent_sum += con_sentiment(con)\n",
    "                        lines += 1\n",
    "                    if lines == 0:\n",
    "                        # If there were no lines, the character did not appear\n",
    "                        sentiment_of_character[character_counter][1].append(None)\n",
    "                    else: \n",
    "                        sentiment_of_character[character_counter][1].append(sent_sum / lines)\n",
    "                    if character_counter > len(sentiment_of_character):\n",
    "                        print(\"!!!!!!!!!!!!!!!!!!!!!!!! WRONG\")\n",
    "                    character_counter += 1\n",
    "    # Returns a list of the sentiments for that character for each chapter of that book\n",
    "    return sentiment_of_character"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162dec3",
   "metadata": {},
   "source": [
    "### ```sent_book(path_to_book)```\n",
    ">Calculates the sentiment for a book on chapter basis. In this function each chapter of a book is read in and the sentiment for the text is calculated. This allows us to see how the sentiment for a book changes as it progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacc7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: The path to a book.\n",
    "Output: A list of sentiments for each chapter of the book.\n",
    "\"\"\"\n",
    "def sent_book(path_to_book):\n",
    "    chapters = os.listdir(path_to_book)\n",
    "\n",
    "    # Making a data table (char_list)x(num_chapters) to hold sentiments for each char in each chap\n",
    "    # tuple list with tuples (character, [sent chapter1, sent chapter2, ...])\n",
    "    sentiments_by_chapter = []\n",
    "    \n",
    "    for chapter in chapters:\n",
    "        if \"replaced\" in chapter:\n",
    "            with open(path_to_book + chapter) as f:\n",
    "                raw = f.read()\n",
    "            sentiments_by_chapter.append(analyzer.polarity_scores(raw)[\"compound\"])\n",
    "    # Returns a list of the sentiments for that character for each chapter of that book\n",
    "    return sentiments_by_chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb626d9f",
   "metadata": {},
   "source": [
    "### ```sent_group(group, label, book_list)```\n",
    ">This function calculates the average sentiments for all of the names given in ```group``` and returns it as as the sentiment for the name from ```label_group```. The sentiments are calculated from the books given in ```book_list```. e.g. given the list of names of Gryffindor students, with label \"Gryffindor\" returns a tuple (\"Gryffindor\", sentiment list), where the sentiment list contains the average sentiment for each chapter for those students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgsent_group(group, label, book_list, sentences):\n",
    "    # Count number of chapters\n",
    "    num_chapters = 0\n",
    "    for book in book_list:\n",
    "        for chapter in os.listdir(book):\n",
    "            if \"replaced\" in chapter:\n",
    "                num_chapters += 1\n",
    "    #print(f\"num_chapters = {num_chapters}\")\n",
    "    sent_chapters = [0] * num_chapters\n",
    "    sent_group = (label, sent_chapters)\n",
    "    \n",
    "    #print(f\"length of sent_chapters = {len(sent_chapters)}\")\n",
    "    #print(f\"length of sent_group[1] = {len(sent_group[1])}\")\n",
    "    \n",
    "    # Counter for current chapter\n",
    "    c = 0\n",
    "    \n",
    "    # For each book in the list\n",
    "    for book in book_list:  \n",
    "        # For each chapter going by numbering\n",
    "        for chapter in os.listdir(book):\n",
    "            if \"replaced\" in chapter:\n",
    "                # Init counter for counting occurences in chapter for average\n",
    "                occurences = 0\n",
    "\n",
    "                # Read in the chapter\n",
    "                with open(book + chapter) as f:\n",
    "                        raw = f.read()\n",
    "                tokens = nltk.word_tokenize(raw)\n",
    "                # Prepare nltk text\n",
    "                text = nltk.Text(tokens)\n",
    "\n",
    "                # For each member of the group\n",
    "                for member in group:\n",
    "                    # Make concordance for that member for that chapter\n",
    "                    con_list = text.concordance_list(member, width = sentences * average_length_of_sentence)\n",
    "\n",
    "                    # For each concordance line in the list\n",
    "                    for con in con_list:\n",
    "                        # Calculate the sentiment\n",
    "                        sent = con_sentiment(con)\n",
    "                        if sent != 0:\n",
    "                            # Sum up the sentiment for that chapter for that member\n",
    "                            # with sentiments for all other members of group\n",
    "                            #print(f\"c = {c}\")\n",
    "                            sent_group[1][c] += sent\n",
    "                            occurences += 1\n",
    "                # Divide by the total number of occurences \n",
    "                if occurences == 0:\n",
    "                    sent_group[1][c] = None\n",
    "                else:\n",
    "                    sent_group[1][c] = sent_group[1][c] / occurences\n",
    "                c += 1\n",
    "    return sent_group                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896ede13",
   "metadata": {},
   "source": [
    "### ```plot_sentiments(sentiment_by_character, figure_text, xs_vertical_lines, show_labels)```\n",
    ">The functions takes a list of tuples, where each tuple contains a name and a list of sentiments. A figure text, a list of tuples for placing vertical lines with labels, and a ```True```/```False```flag for show labels. This function may take the result of ```sent_char_books``` a sinput for the list of tuples with names and sentiments. This allows for fast and simple plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: A list of tuples containing a name and a sentiment list, a figure text, \n",
    "       a list of tuples with labels and coordinates for vertical lines, and a\n",
    "       true/false value for showing labels.\n",
    "Output: void, shows a plot\n",
    "\"\"\"\n",
    "def plot_sentiments(sentiment_by_character, figure_text, xs_vertical_lines, show_legend):\n",
    "    # Init iterator\n",
    "    color = iter(cm.rainbow(np.linspace(0, 3, len(sentiment_by_character)*3)))\n",
    "    plt.xlim(0, len(sentiment_by_character[0][1]))\n",
    "    \n",
    "    for name, sentiments in sentiment_by_character:\n",
    "        # Try to give colors according the name associated with the sentiments\n",
    "        if (\"Gryffindor\" in name):\n",
    "            c = \"red\"\n",
    "            a = 1\n",
    "        elif (\"Slytherin\" in name and name != \"Salazar_Slytherin\"):\n",
    "            c = \"green\"\n",
    "            a = 1\n",
    "        elif (\"Hufflepuff\" in name):\n",
    "            c = \"yellow\"\n",
    "            a = 1\n",
    "        elif (\"Ravenclaw\" in name):\n",
    "            c = \"blue\"\n",
    "            a = 1\n",
    "        elif (\"Average\" in name):\n",
    "            c = \"black\"\n",
    "            a = 1\n",
    "        else:\n",
    "            c = next(color)\n",
    "            a = 0.5\n",
    "        plt.plot(sentiments, c=c, alpha=a, label=name)\n",
    "    \n",
    "    # Make horizontal lines to indicate the neutral region\n",
    "    plt.axhline(y = 0.05, color =\"purple\", linestyle = '--', label=\"Neutral\")\n",
    "    plt.axhline(y = -0.05, color =\"purple\", linestyle = '--')\n",
    "    \n",
    "    # If vertical lines for book has been specified insert them\n",
    "    for book, label, vertical_line in xs_vertical_lines:\n",
    "        plt.axvline(x = vertical_line, color = 'black')\n",
    "        \n",
    "    # Get list of labels and vertical_lines\n",
    "    if xs_vertical_lines != []:\n",
    "        xs = []\n",
    "        labels = []\n",
    "        for book, x_coordinate, label in xs_vertical_lines:\n",
    "            xs.append(x_coordinate)\n",
    "            labels.append(label)\n",
    "        plt.xticks(labels, xs ,rotation=45)\n",
    "\n",
    "    # If legend has been requested\n",
    "    if show_legend:\n",
    "        plt.legend()\n",
    "\n",
    "    #plt.xlabel('Chapter')\n",
    "    plt.ylabel('Average sentiment')\n",
    "    plt.figtext(.5, -0.2, figure_text, ha=\"center\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dfdb32",
   "metadata": {},
   "source": [
    "## Sentiment for books\n",
    ">First we want to explore how the sentiment is throughout the books. We have two ideas for measuring this: Take each chapter as a text and have VADER analyze the sentiment of that text for us. Or for each character from our list of characters, make concordance for each chapter for that character, and divide it by the total number of concordance lines for that chapter. We are going to test these two methods out to see which is more expressive:\n",
    "\n",
    ">We start by defining some list needed for plotting and reading in all the books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289be994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuple list containing the first chapter of the next book, e.g. (\"B1\", 18), indicates\n",
    "# all chapters up to 18 excluded are from book 1\n",
    "book_list_wchapter = [(\"B1\", \"Philosopher's Stone\", 0), \n",
    "                      (\"B2\", \"Chamber of Secrets\", 18),\n",
    "                      (\"B3\", \"Prisoner of Azkaban\", 35), \n",
    "                      (\"B4\", \"Goblet of Fire\", 57), \n",
    "                      (\"B5\", \"Order of the Phoenix\", 94), \n",
    "                      (\"B6\", \"Half-Blood Prince\", 134), \n",
    "                      (\"B7\", \"Deathly Hallows\", 162)]\n",
    "# Lists of paths to the folders holding the text from the chapters\n",
    "book_list = [\"B1/\", \"B2/\", \"B3/\", \"B4/\", \"B5/\", \"B6/\", \"B7/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baed21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init list to hold sentiment values\n",
    "series_sent = []\n",
    "# Compute and append the sentiment values for the seven books\n",
    "series_sent += sent_book(\"B1/\")\n",
    "series_sent += sent_book(\"B2/\")\n",
    "series_sent += sent_book(\"B3/\")\n",
    "series_sent += sent_book(\"B4/\")\n",
    "series_sent += sent_book(\"B5/\")\n",
    "series_sent += sent_book(\"B6/\")\n",
    "series_sent += sent_book(\"B7/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a43563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure text\n",
    "sent_by_chapter = \"Sentiment by chapter for entire series analyzed one chapter at a time\"\n",
    "# Adjust for a wider figure size\n",
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "# Plot the sentiment values for all of the books when VADER analyzed each chapter as a whole text\n",
    "plot_sentiments([(\"Sentiment for series\", series_sent)], sent_by_chapter, book_list_wchapter, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b23f81",
   "metadata": {},
   "source": [
    ">The above figure does not convey changes in the book very well, at most it seems that we can get an idea of the overall tone of the chapter, but not how it relates to the other chapters or how the story evolves and changes. \n",
    "\n",
    ">For the next part we are going to try the approach with making concordance for all of the characters for each chapter and taking the average. However ```concordance_list``` uses a default width of 80 characters around the string that it is making concordance for. First we have to investigate if this default value is good. To investigate this we first determine the average length in characters for the books:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c75fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365a3d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What the average length of a sentence in harry potter? in characters\n",
    "# Read in all of the chapters and count the length of the sentences, divide by the number ound\n",
    "# use this for average to determine how many sentences we want included for each concordance?\n",
    "number_of_sentences = 0\n",
    "number_of_characters = 0\n",
    "for book in book_list:\n",
    "    for chapter in os.listdir(book):\n",
    "        if \"replaced\" in chapter:\n",
    "            with open(book + chapter) as f:\n",
    "                raw = f.read()\n",
    "            sentences = nltk.sent_tokenize(raw)\n",
    "            for sentence in sentences:\n",
    "                number_of_characters += len(sentence)\n",
    "                number_of_sentences += 1\n",
    "average_characters_in_sent = number_of_characters / number_of_sentences\n",
    "print(average_characters_in_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df411d7a",
   "metadata": {},
   "source": [
    ">The average sentence in the books is 114 characters long. Our default width for a concordance should then be 114 characters, assuming the character name is in the middle of the sentence and has an even length. So now we can test out how many sentences should be used. We are going to test with a smaller size of a half sentence, default, one sentence, two, three, and four to start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83176332",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_sentences_test = []\n",
    "average_length_of_sentence = 79\n",
    "con_sentences_test.append(avgsent_group([\"Harry_Potter\"], \"Harry Potter Default\", [\"B1/\"], 1))\n",
    "average_length_of_sentence = 114\n",
    "con_sentences_test.append(avgsent_group([\"Harry_Potter\"], \"Harry Potter 1\", [\"B1/\"], 1))\n",
    "con_sentences_test.append(avgsent_group([\"Harry_Potter\"], \"Harry Potter 2\", [\"B1/\"], 2))\n",
    "con_sentences_test.append(avgsent_group([\"Harry_Potter\"], \"Harry Potter 3\", [\"B1/\"], 3))\n",
    "con_sentences_test.append(avgsent_group([\"Harry_Potter\"], \"Harry Potter 4\", [\"B1/\"], 4))\n",
    "plot_sentiments(con_sentences_test, \"Average sentiment for Harry Potter in book one, with 0.5 sentences used for concordance\", [], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31497fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_sentences_test = []\n",
    "con_sentences_test.append(avgsent_group([\"Harry_Potter\"], \"Harry Potter 8\", [\"B1/\"], 8))\n",
    "con_sentences_test.append(avgsent_group([\"Harry_Potter\"], \"Harry Potter 16\", [\"B1/\"], 16))\n",
    "con_sentences_test.append(avgsent_group([\"Harry_Potter\"], \"Harry Potter 32\", [\"B1/\"], 32))\n",
    "con_sentences_test.append(avgsent_group([\"Harry_Potter\"], \"Harry Potter 64\", [\"B1/\"], 64))\n",
    "plot_sentiments(con_sentences_test, \"Average sentiment for Harry Potter in book one, with differening number of sentences used for concordance\", [], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34111b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_test_all = []\n",
    "con_test_all.append(avgsent_group(character_names, \"All characters, 2 sentences con\", [\"B1/\"], 2))\n",
    "con_test_all.append(avgsent_group(character_names, \"All characters, 3 sentences con\", [\"B1/\"], 3))\n",
    "con_test_all.append(avgsent_group(character_names, \"All characters, 4 sentences con\", [\"B1/\"], 4))\n",
    "con_test_all.append(avgsent_group(character_names, \"All characters, 32 sentences con\", [\"B1/\"], 32))\n",
    "con_test_all.append((\"book 1 sent\", sent_book(\"B1/\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fefa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiments(con_test_all, sent_by_chapter, [], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89004d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ffcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character tuple list\n",
    "characters = []\n",
    "\n",
    "# Read the character with their attributes from our .csv file\n",
    "with open(\"HP_characters.csv\", \"r\", encoding=\"utf8\") as sent_file:\n",
    "    csv_reader_characters = csv.reader(sent_file, delimiter=\",\")\n",
    "    for row in csv_reader_characters:\n",
    "        name = row[0].replace(' ', '_')\n",
    "        parentage = row[1]\n",
    "        house = row[2]\n",
    "        occupation = row[3]\n",
    "        characters.append((name, parentage, house, occupation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e4990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the character names from our list with attributes\n",
    "character_names = [n for n, b, h, o in characters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average sentiment for each chapter\n",
    "avgsent_all = avgsent_group(character_names, \"Average sentiment of all characters\", book_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e22344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_books = \"Average sentiment from concordance of character names throughout the books.\"\n",
    "plot_sentiments([avgsent_all], sentiment_books, book_list_wchapter, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14d51c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38f1bee0",
   "metadata": {},
   "source": [
    "## Sentiment for houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ef33cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gryffindors = [n for n, p, h, o in characters if h == \"Gryffindor\"]\n",
    "hufflepuffs = [n for n, p, h, o in characters if h == \"Hufflepuff\"]\n",
    "ravenclaws = [n for n, p, h, o in characters if h == \"Ravenclaw\"]\n",
    "slytherins = [n for n, p, h, o in characters if h == \"Slytherin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of characters from Gryffindor: {len(gryffindors)}\")\n",
    "print(f\"Number of characters from Hufflepuff: {len(hufflepuffs)}\")\n",
    "print(f\"Number of characters from Ravenclaw: {len(ravenclaws)}\")\n",
    "print(f\"Number of characters from slytherin: {len(slytherins)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsent_gryffindor = avgsent_group(gryffindors, \"Gryffindors\", book_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7bd04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsent_gryffindor = avgsent_group(gryffindors, \"Gryffindors\", book_list)\n",
    "avgsent_hufflepuff = avgsent_group(hufflepuffs, \"Hufflepuffs\", book_list)\n",
    "avgsent_ravenclaw = avgsent_group(ravenclaws, \"Ravencalws\", book_list)\n",
    "avgsent_slytherin = avgsent_group(slytherins, \"Slytherins\", book_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d71261",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sent_list = [avgsent_gryffindor, \n",
    "                 avgsent_slytherin,\n",
    "                 avgsent_hufflepuff,\n",
    "                 avgsent_ravenclaw]\n",
    "plot_sentiments(avg_sent_list, \"Average sentiment for the four houses throughout the books\", book_list_wchapter, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Gryffindors\"\n",
    "gryff_sents = sent_chars_book_list(gryffindors, book_list) + [avgsent_gryffindor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff3ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gryff_sent = \"Average sentiments for Gryffindor, and sentimens for all Gryffindors\"\n",
    "plot_sentiments(gryff_sents, text_gryff_sent, book_list_wchapter, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97185b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at graph above maybe purple does not follow the trend?\n",
    "# maybe purple is dumbledore, trying to remove:\n",
    "tup_dict = dict(gryff_sents)\n",
    "tup_dict.pop('Albus_Dumbledore')\n",
    "tup_dict.pop('Gryffindors')\n",
    "gryff_sent = list(tuple(tup_dict.items()))\n",
    "\n",
    "# Dumbledore has not been removed?\n",
    "\n",
    "#gryffindors.remove(\"Albus_Dumbledore\")\n",
    "gryff_sent = gryff_sent + [avgsent_group(gryffindors, \"Gryffindors\", book_list)]\n",
    "plot_sentiments(gryff_sents, text_gryff_sent, book_list_wchapter, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Slytherins\"\n",
    "slyth_sents = sent_chars_book_list(slytherins, book_list) + [avgsent_slytherin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7192fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_slyth_sent = \"Average sentiments for Slytherin, and sentimens for all Slytherins\"\n",
    "plot_sentiments(slyth_sents, text_slyth_sent, book_list_wchapter, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Hufflepuffs\"\n",
    "huff_sents = sent_chars_book_list(hufflepuffs, book_list) + [avgsent_hufflepuff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unexpected plot, hvorfor er alle kapitler fra første bog ikke med? Jf. streg for første bog ovenfor\n",
    "text_huff_sent = \"Average sentiments for Hufflepuff, and sentimens for all Hufflepuffs\"\n",
    "plot_sentiments(huff_sents, text_huff_sent, book_list_wchapter, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Ravenclaws\"\n",
    "rave_sents = sent_chars_book_list(ravenclaws, book_list) + [avgsent_ravenclaw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad80a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unexpected plot, hvorfor er der ikke plot fra 0 og frem?\n",
    "text_rave_sent = \"Average sentiments for Ravenclaw, and sentimens for all Ravenclaws\"\n",
    "plot_sentiments(rave_sents, text_rave_sent, book_list_wchapter, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8e3ad4",
   "metadata": {},
   "source": [
    "## Highest and lowest sentiments\n",
    ">Investigating which characters have the highest and lowest sentiments by summing up their average sentiment values for each chapter they appeared in, and dividing by the number of chapters they appeared in into a sentiment score for that character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadc08dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsent_all_individual = sent_chars_book_list(character_names, book_list)\n",
    "character_sent_scores = []\n",
    "for name, sent_list in avgsent_all_individual:\n",
    "    sent_score = 0\n",
    "    sent_sum = 0\n",
    "    chapter_occurences = 0\n",
    "    for sent in sent_list:\n",
    "        if sent != None:\n",
    "            sent_sum += sent\n",
    "            lines += 1\n",
    "    sent_score = sent_sum\n",
    "    character_sent_scores.append((name, sent_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eae42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://bobbyhadz.com/blog/python-sort-list-of-tuples-by-second-element\n",
    "sorted_list = sorted(\n",
    "    character_sent_scores,\n",
    "    key=lambda t: t[1]\n",
    ")\n",
    "top_names = [n for n, s in sorted_list[-5:]]\n",
    "top = [(n, l) for n, l in avgsent_all_individual if n in top_names]\n",
    "bottom_names = [n for n, s in sorted_list[0:5]]\n",
    "bottom = [(n, l) for n, l in avgsent_all_individual if n in bottom_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41cf7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_text = \"Sentiment values of 5 highest sentiment, with total average for comparison.\"\n",
    "plot_sentiments([avgsent_all] + top, top_text, book_list_wchapter, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2119a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_george = [(n, l) for n, l in avgsent_all_individual if n in [\"Fred_Weasley\", \"George_Weasley\"]]\n",
    "fred_george_text = \"Sentiment for Fred and George Weasley\"\n",
    "plot_sentiments(fred_george, fred_george_text, book_list_wchapter, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b983b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_text = \"Sentiment values of 5 lowest sentiment, with total average for comparison.\"\n",
    "plot_sentiments([avgsent_all] + bottom, bottom_text, book_list_wchapter, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce798b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sirius_black = [(n, l) for n, l in avgsent_all_individual if n in [\"Sirius_Black\"]]\n",
    "sirius_black_text = \"Sentiment for Sirius Black\"\n",
    "plot_sentiments(sirius_black, sirius_black_text, book_list_wchapter, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0b2e5c",
   "metadata": {},
   "source": [
    "## Sentiment for main characters\n",
    ">Who are the main characters, definetely Harry, Ron, Hermione. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca34a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_character_list = [\"Harry_Potter\", \"Ronald_Weasley\", \"Hermione_Granger\"]\n",
    "main_characters = [(n, l) for n, l in avgsent_all_individual if n in main_character_list]\n",
    "bottom_text = \"Sentiment values of 5 lowest sentiment, with total average for comparison.\"\n",
    "plot_sentiments([avgsent_all] + main_characters, bottom_text, book_list_wchapter, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fb792f",
   "metadata": {},
   "source": [
    "# Checking if there are characters that should be in the book, but have sentiment None in all chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb01e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Characters that should be in the book but have no sentiments?\n",
    "character_names = [n for n, b, h, o in characters]\n",
    "avgsent_all_chars = sent_chars_book_list(character_names, book_list)\n",
    "for n, l in avgsent_all_chars:\n",
    "    all_is_none = True\n",
    "    for i in l:\n",
    "        if i != None:\n",
    "            all_is_none = False\n",
    "    if all_is_none == True:\n",
    "        print(n)\n",
    "        \n",
    "# Justin_Finch-Fletchley <- B4 ch18, men er måske det eneste sted? Og han siger ikke noget\n",
    "# Arabella_Figg <- B7 ch2, lader til at være erstattet med AraBellatrix_Lestrange_Figg\n",
    "# Nicholas_de_Mimsy-Porpington <- B1 ch7, han står der men bliver ikke fundet? Det står præcist sådan her så forstår det ikke lige\n",
    "# Patrick_Delaney-Podmore <- Spøgelse, måske ikke vigtig?\n",
    "# Bartemius_Crouch_Junior <- noget med at han har forklædt sig som Alastor_Moody i det meste af bog 4 (måske?), og vidst kun rigtigt er med i den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8afd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"B1/\" + \"replaced_ch8.txt\") as f:\n",
    "    raw = f.read()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "print(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
